{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet de nettoyer notre dataset en éliminant ou en remplaçant les données manquantes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Il faut commencer par indiquer quelles sont les valeurs manquantes de notre dataset \n",
    "\n",
    "## Généralement elles sont indiquées par 'np.nan' comme dans l'exemple ci-dessous\n",
    "\n",
    "X = np.array([[10, 3],\n",
    "              [0, 4],\n",
    "              [5, 3],\n",
    "             [np.nan, 3]])\n",
    "### Mais il peut arriver d'avoir -99, +l'infini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  3.],\n",
       "       [ 0.,  4.],\n",
       "       [ 5.,  3.],\n",
       "       [ 5.,  3.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notre travail est justement d'identifier quelles valeurs manquantes on cherche à noettoyer\n",
    "\n",
    "## On peut alors créer plusieurs séries de SimpleImputer piur filtrer plusieurs types de variables\n",
    "\n",
    "### Il faut ensuite définir la 'strategy' pour remplacer ces valeurs, il en existe 4 majeures :\n",
    "    \n",
    "    # Moyenne\n",
    "    # Mediane\n",
    "    # Plusfréquente 'most\n",
    "    # Une constante \n",
    "    \n",
    "imputer = SimpleImputer(missing_values=np.nan,\n",
    "                       strategy='mean')\n",
    "\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image = plt.imread('Simple_Imputer.png')\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Il remplace les valeures manquantes à un certain échantillon par les valeurs qui correspondent aux autres observations les plus \n",
    "# similaires, par les valeurs des plus proches voisins \n",
    "\n",
    "## C'est donc un algo de KNearestNeighbors classique dans lequel on va donc choisir un nombre de voisins à considérer\n",
    "\n",
    "X = np.array([[1, 100],\n",
    "             [2, 30],\n",
    "             [3, 15],\n",
    "             [np.nan, 20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 100.],\n",
       "       [  2.,  30.],\n",
       "       [  3.,  15.],\n",
       "       [  3.,  20.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=1)\n",
    "imputer.fit_transform(X)\n",
    "\n",
    "# On voit que la valeur la plus proche de 20 est 15, et que la valeurs associée est 2, c'est donc notre résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut alors penser à utliser GridSearchCV pour trouver le nombre de voisin otpimal ~ permettant le meilleur remplacement des NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MissingIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "# Indique où est-ce qu'il manque des données dans notre dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MissingIndicator().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cela peut être très utile de créer une colonne dans notre dataset qui indiquerait si oui ou non il nous manque plusieurs \n",
    "# informations pour un certain échantillons\n",
    "\n",
    "## Dans le cas du Titanic, un passager qui n'a pas payé et qui n'a pas de classe est surement en réalité un m'embre d'équipage ! \n",
    "\n",
    "### Pour cela on utilise la fonction make_union qui permet de traiter de façon différente plusieurs données dans un même dataset,\n",
    "### càd de façon parallèle, puis de concaténer nos résultats dans un seul et même tableau \n",
    "\n",
    "from sklearn.pipeline import make_union\n",
    "\n",
    "X = np.array([[1, 100],\n",
    "             [2, 30],\n",
    "             [3, 15],\n",
    "             [np.nan, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 100.,   0.,   0.],\n",
       "       [  2.,  30.,   0.,   0.],\n",
       "       [  3.,  15.,   0.,   0.],\n",
       "       [-99., -99.,   1.,   1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On commence donc par créer une Pipeline \n",
    "\n",
    "pipeline = make_union(SimpleImputer(strategy='constant', fill_value=-99),\n",
    "                      MissingIndicator())\n",
    "\n",
    "pipeline.fit_transform(X)\n",
    "\n",
    "# On obtient alors d'un cotés (droit), les colonnes qui ont subit SimpleImputer, donc on garde nos informations sur la classe du \n",
    "# du passager de le prix de son ticket\n",
    "\n",
    "## De l'autre une indication sur le fait que cela soit plutot un passager ou un matelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : Le manque d'information EST une information !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "X = titanic[['pclass', 'age']]\n",
    "y = titanic['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(KNNImputer(), SGDClassifier())\n",
    "\n",
    "# Le fait d'utiliser le KNNImputer  plutôt que d'utiliser une fonction Pandas comme .fillna() pour faire de l'imputation, va nous\n",
    "# permettre d'utiliser notre 'transformer' avec GrisSearchCv afin d'en optimiser ses caractéristiques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence donc par créer un dictonnaire, dans lequel on va mettre les paramètres que l'on souhaite optimiser \n",
    "\n",
    "params = { \n",
    "'knnimputer__n_neighbors': [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de la on peut créer une GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(model, param_grid = params, cv = 5)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Maintenant que cette grille est définie, on va l'entrainer avec X_train & y_train\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=1)),\n",
       "                ('sgdclassifier', SGDClassifier())])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_\n",
    "\n",
    "# On a donc pu optimiser le nombre de paramètres de notre KNNImputer grâce à GridSearchCV, ce qui n'aurait pas été possible avec \n",
    "# des fonctions Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
